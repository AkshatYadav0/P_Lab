{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00ed732-c657-4db0-85b7-167907b382b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GRU + Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5842913-716a-49ff-8f46-2d5e5a175c6d",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef11f2fb-5269-4c19-8c01-9006215208e9",
   "metadata": {},
   "source": [
    "**This notebook extends the GRU Classifier model (movie watching) described in the [paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008943)  by adding an `Attention Layer`**\n",
    "\n",
    "Attention was first presented by Dzmitry Bahdanau, et al. in their paper [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd10e05-5e39-4c34-897a-67151f7179e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d315492-15a6-46b8-8527-1e65f9712314",
   "metadata": {},
   "source": [
    "**Data provided is already preprocessed but needs to be converted in model usabale format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6f36f2-a0bf-4460-bc88-4906ed055872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1556b2d-782b-41c5-ade7-86913ca18b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['testretest', 'twomen', 'bridgeville', 'pockets', 'overcome', 'inception', 'socialnet', 'oceans', 'flower', 'hotel', 'garden', 'dreary', 'homealone', 'brokovich', 'starwars'])\n"
     ]
    }
   ],
   "source": [
    "with open('HCP_movie_watching.pkl','rb') as f:\n",
    "    TS = pickle.load(f)\n",
    "print(TS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187648f5-bbf9-4131-bfd9-b9522b6ea286",
   "metadata": {},
   "source": [
    "## Dataset organization\n",
    "`TS` is a dictionary with movie names as keys\n",
    "\n",
    "Value against each key is a numpy array of dimensions `[#participants, #time points, #ROIs]`\n",
    "\n",
    "Note that the testretest movie appears on all 4 runs for a participant, therefore the value has dimensions `[#runs, #participants, #time points, #ROIs]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43363337-d949-448f-b761-99a9897a4f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testretest (4, 176, 84, 300)\n",
      "twomen (176, 245, 300)\n",
      "bridgeville (176, 222, 300)\n",
      "pockets (176, 189, 300)\n",
      "overcome (176, 65, 300)\n",
      "inception (176, 227, 300)\n",
      "socialnet (176, 260, 300)\n",
      "oceans (176, 250, 300)\n",
      "flower (176, 181, 300)\n",
      "hotel (176, 186, 300)\n",
      "garden (176, 205, 300)\n",
      "dreary (176, 143, 300)\n",
      "homealone (176, 233, 300)\n",
      "brokovich (176, 231, 300)\n",
      "starwars (176, 256, 300)\n"
     ]
    }
   ],
   "source": [
    "rel = {}\n",
    "l = 0\n",
    "for movie_name, ts in TS.items():\n",
    "    rel[movie_name] = l\n",
    "    l += 1\n",
    "    print(movie_name, ts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abfc207-6280-47e7-92c3-d77e5f908289",
   "metadata": {},
   "source": [
    "## Padding sequences\n",
    "\n",
    "To deal with varying `time points`. For data with `time points < seq_length(self defined)` , I have paded them with 0s. For data with `time points > seq_length(self defined)`, I have split the data into 2 section first, into `[ : seq_length]`, second into `[data_time_point-seq_length : ]`. I have used the `seq_length = 198` (average time_point mentioned in the paper).\n",
    "\n",
    "**Final `features` array is a 2D array, with shape = `(seq_length,300)`.**\n",
    "\n",
    "The following block shows above mentioned discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "607d6a22-aa55-4a97-81d0-1298f5886666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n"
     ]
    }
   ],
   "source": [
    "train_feature = []\n",
    "test_feature  = []\n",
    "train_target  = []\n",
    "test_target   = []\n",
    "seq_length    = 198\n",
    "\n",
    "for movie_name, ts in TS.items():\n",
    "    pep = 0\n",
    "    if movie_name != \"testretest\":\n",
    "        for i in ts:\n",
    "            pep += 1\n",
    "            if (pep <= 100):\n",
    "                if i.shape[0]>seq_length:\n",
    "                    k = i[:seq_length][:]\n",
    "                    train_feature.append(k)\n",
    "                    train_target.append(rel[movie_name])\n",
    "                    \n",
    "                    k = i[i.shape[0]-seq_length:][:]\n",
    "                    train_feature.append(k)\n",
    "                    train_target.append(rel[movie_name])\n",
    "                \n",
    "                elif i.shape[0]<seq_length:\n",
    "                    k = [[0]*300]*seq_length\n",
    "                    k[seq_length-i.shape[0]:] = i\n",
    "                    train_feature.append(k)\n",
    "                    train_target.append(rel[movie_name])\n",
    "                else:\n",
    "                    train_feature.append(i)\n",
    "                    train_target.append(rel[movie_name])\n",
    "\n",
    "            else:\n",
    "                if i.shape[0]>seq_length:\n",
    "                    k = i[:seq_length][:]\n",
    "                    test_feature.append(k)\n",
    "                    test_target.append(rel[movie_name])\n",
    "                   \n",
    "                    k = i[i.shape[0]-seq_length:][:]\n",
    "                    test_feature.append(k)\n",
    "                    test_target.append(rel[movie_name])\n",
    "                \n",
    "                elif i.shape[0]<seq_length:\n",
    "                    k = [[0]*300]*seq_length\n",
    "                    k[seq_length-i.shape[0]:] = i\n",
    "                    test_feature.append(k)\n",
    "                    test_target.append(rel[movie_name])\n",
    "                else:\n",
    "                    test_feature.append(i)\n",
    "                    test_target.append(rel[movie_name])\n",
    "        print(pep)\n",
    "    else:\n",
    "        for jj in ts:\n",
    "            pep = 0\n",
    "            for i in jj:\n",
    "                pep += 1\n",
    "                if (pep <= 100):\n",
    "                    if i.shape[0]>seq_length:\n",
    "                        k = i[:seq_length][:]\n",
    "                        train_feature.append(k)\n",
    "                        train_target.append(rel[movie_name])\n",
    "\n",
    "                        k = i[i.shape[0]-seq_length:][:]\n",
    "                        train_feature.append(k)\n",
    "                        train_target.append(rel[movie_name])\n",
    "\n",
    "                    elif i.shape[0]<seq_length:\n",
    "                        k = [[0]*300]*seq_length\n",
    "                        k[seq_length-i.shape[0]:] = i\n",
    "                        train_feature.append(k)\n",
    "                        train_target.append(rel[movie_name])\n",
    "                    else:\n",
    "                        train_feature.append(i)\n",
    "                        train_target.append(rel[movie_name])\n",
    "\n",
    "                else:\n",
    "                    if i.shape[0]>seq_length:\n",
    "                        k = i[:seq_length][:]\n",
    "                        test_feature.append(k)\n",
    "                        test_target.append(rel[movie_name])\n",
    "\n",
    "                        k = i[i.shape[0]-seq_length:][:]\n",
    "                        test_feature.append(k)\n",
    "                        test_target.append(rel[movie_name])\n",
    "\n",
    "                    elif i.shape[0]<seq_length:\n",
    "                        k = [[0]*300]*seq_length\n",
    "                        k[seq_length-i.shape[0]:] = i\n",
    "                        test_feature.append(k)\n",
    "                        test_target.append(rel[movie_name])\n",
    "                    else:\n",
    "                        test_feature.append(i)\n",
    "                        test_target.append(rel[movie_name])\n",
    "            print(pep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c547f-dd11-4881-8f6d-bf9a04787a6a",
   "metadata": {},
   "source": [
    "## Training, Validation, Test\n",
    "\n",
    "With the data in required shape, The following shows the split into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31cc2a9b-713e-4b6a-a469-944aae53384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(np.array(train_feature)).float(),torch.from_numpy(np.array(train_target)).float())\n",
    "test_data  = TensorDataset(torch.from_numpy(np.array(test_feature)).float(),torch.from_numpy(np.array(test_target)).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6deceaea-cf4f-4516-8bea-dd4cbd609de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2700, 2052)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data),len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b08f7b66-b862-4421-be4b-d1bf95336c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "batch_size = 32\n",
    "valid_data  = 0.237\n",
    "t_train     = len(train_data)\n",
    "data_no     = list(range(t_train))\n",
    "np.random.shuffle(data_no)\n",
    "split_no    = int(np.ceil(valid_data*t_train))\n",
    "train,valid = data_no[split_no:],data_no[:split_no]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train)\n",
    "valid_sampler = SubsetRandomSampler(valid)\n",
    "\n",
    "train_loader  = DataLoader(train_data,batch_size=batch_size,sampler=train_sampler)\n",
    "valid_loader  = DataLoader(train_data,sampler=valid_sampler,batch_size=batch_size)\n",
    "test_loader   = DataLoader(test_data, batch_size=batch_size,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "712778a9-8de2-43c0-a828-3e0f10e1d900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8b16bb6-a738-453b-b643-614545dff6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 20, 65)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader),len(valid_loader),len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0164e572-1cde-43d2-9962-8807168c9f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 198, 300])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(train_loader).next()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94466fed-c399-40ae-bcac-6531df7eb884",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b125b2a-bb8d-4ce6-9f0a-8e069a79df24",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068beeed-357c-4d28-a104-eeaac7407776",
   "metadata": {},
   "source": [
    "## Implementing the `Attention` Model\n",
    "\n",
    "The following figures shows the idea behind it\n",
    "\n",
    "\n",
    "<img src=\"attntion1.png\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52bc285c-cd82-4567-b0c1-278785fda899",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim, seq_len, bias=False, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.supports_masking = True\n",
    "        self.bias       = bias\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len    = seq_len\n",
    "        \n",
    "        weight = torch.zeros(hidden_dim, 1)\n",
    "        nn.init.kaiming_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        \n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.zeros(seq_len))\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "\n",
    "        eij = torch.mm(x.contiguous().view(-1, self.hidden_dim ), self.weight).view(-1, self.seq_len)\n",
    "        \n",
    "        if self.bias:\n",
    "            eij = eij + self.b\n",
    "            \n",
    "        eij = torch.tanh(eij)\n",
    "        a = torch.exp(eij)\n",
    "        \n",
    "        if mask is not None:\n",
    "            a = a * mask\n",
    "\n",
    "        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n",
    "        weighted_input = x * torch.unsqueeze(a, -1)\n",
    "        \n",
    "        return torch.sum(weighted_input, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d18314-cd91-4a77-ac9e-a996e32f9f26",
   "metadata": {},
   "source": [
    "## `GRU Classifier` Model as described in the [paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008943)\n",
    "<img src=\"gru.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03f4c547-27bc-4fd2-891b-2e47de2cefca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim,hidden_dim,n_layers,att=True,drop_prob=0.000006):\n",
    "        super(GRU_RNN, self).__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.n_layers   = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.att        = att\n",
    "        \n",
    "        self.gru       = nn.GRU(input_dim,hidden_dim,num_layers=n_layers,dropout=drop_prob,batch_first=True)\n",
    "        self.linear    = nn.Linear(hidden_dim,output_dim)\n",
    "        if att:\n",
    "            self.attention = Attention(hidden_dim, 198)\n",
    "        \n",
    "        self.dropout   = nn.Dropout(0.3)\n",
    "        self.func      = nn.Softmax(dim = -1)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x,hidden = self.gru(x,hidden)\n",
    "        \n",
    "        if self.att:\n",
    "            x = self.attention(x)\n",
    "        else:\n",
    "            x = x[:, -1, :]\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        sig_out = self.func(x)\n",
    "        \n",
    "        return sig_out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782f2153-8768-40da-ad15-a1f3747840e4",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcfbb3b5-9aff-4dc3-b88f-93ffc79cd85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs,train_loader,net,valid_loader,optimzer,criterion,att=True):\n",
    "    val_acc = []\n",
    "    tr_acc = []\n",
    "    \n",
    "    \n",
    "    print_every = 50\n",
    "    clip = 5 # gradient clipping\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    net.train()\n",
    "    valid_losses = []\n",
    "    train_losses = []\n",
    "    for e in range(epochs):\n",
    "        num_correct = 0\n",
    "        h = net.init_hidden(batch_size)\n",
    "        train_loss = []\n",
    "        valid_loss = []\n",
    "        train_acc  = 0.0\n",
    "        valid_acc  = 0.0 \n",
    "        counter = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            counter += 1\n",
    "            if counter == 65:\n",
    "                continue\n",
    "            inputs, labels = inputs.to(device), labels.type(torch.LongTensor).to(device)\n",
    "            h = h.data\n",
    "            net.zero_grad()\n",
    "\n",
    "            output, h = net(inputs, h) \n",
    "            pred = torch.round(output.squeeze()) \n",
    "            top_value, top_index = torch.max(pred,1)\n",
    "            correct_tensor = top_index.eq(labels.float().view_as(top_index))\n",
    "            correct = np.squeeze(correct_tensor.to('cpu').numpy())\n",
    "            num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "        tr_acc.append(num_correct/(len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "\n",
    "        acc = 0.0\n",
    "        val_h = net.init_hidden(batch_size)\n",
    "        val_losses = []\n",
    "        net.eval()\n",
    "        v_c = 0\n",
    "        for inputs, labels in valid_loader:\n",
    "            v_c += 1\n",
    "            #if (v_c == 14):\n",
    "            #    continue\n",
    "            val_h = val_h.data\n",
    "            inputs, labels = inputs.to(device), labels.type(torch.LongTensor).to(device)\n",
    "\n",
    "            output, val_h = net(inputs, val_h)\n",
    "            \n",
    "            pred = torch.round(output.squeeze()) \n",
    "            top_value, top_index = torch.max(pred,1)\n",
    "            correct_tensor = top_index.eq(labels.float().view_as(top_index))\n",
    "            correct = np.squeeze(correct_tensor.to('cpu').numpy())\n",
    "            num_correct += np.sum(correct)\n",
    "            acc = num_correct/(len(train_loader.dataset))\n",
    "            valid_acc += acc.item()\n",
    "\n",
    "            val_loss = criterion(output.squeeze(),labels)\n",
    "            val_losses.append(val_loss.item())\n",
    "            if val_loss.item() <= valid_loss_min:\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, val_loss.item()))\n",
    "                if att:\n",
    "                    torch.save(net.state_dict(), 'RNN_GRU_Att.pt')\n",
    "                else:\n",
    "                    torch.save(net.state_dict(), 'RNN_GRU.pt')\n",
    "                valid_loss_min = val_loss.item()\n",
    "\n",
    "        net.train()\n",
    "        valid_losses.append(np.mean(val_losses))\n",
    "        train_losses.append(np.mean(train_loss))\n",
    "        val_acc.append(valid_acc/len(valid_loader))\n",
    "        print('Epoch: {}/{} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(e+1,epochs,np.mean(train_loss),np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7f4a78c-9568-4b03-905b-e41dd00c79e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs     = 45 \n",
    "input_dim  = 300\n",
    "hidden_dim = 32\n",
    "output_dim = 15\n",
    "n_layers   = 2\n",
    "lr         = 0.006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb106ebb-8426-416c-ada2-830c039d2ed3",
   "metadata": {},
   "source": [
    "## Training with Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57404114-18e9-4aa3-bd8d-083439bb501f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU_RNN(\n",
      "  (gru): GRU(300, 32, num_layers=2, batch_first=True, dropout=6e-06)\n",
      "  (linear): Linear(in_features=32, out_features=15, bias=True)\n",
      "  (attention): Attention()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (func): Softmax(dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model     = GRU_RNN(input_dim, output_dim, hidden_dim, n_layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fba8d73-163a-442f-80ca-03fa23f00d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 2.515430).  Saving model ...\n",
      "Validation loss decreased (2.515430 --> 2.480510).  Saving model ...\n",
      "Validation loss decreased (2.480510 --> 2.400114).  Saving model ...\n",
      "Epoch: 1/45 \tTraining Loss: 2.580829 \tValidation Loss: 2.509023\n",
      "Validation loss decreased (2.400114 --> 2.389253).  Saving model ...\n",
      "Validation loss decreased (2.389253 --> 2.368213).  Saving model ...\n",
      "Validation loss decreased (2.368213 --> 2.342979).  Saving model ...\n",
      "Validation loss decreased (2.342979 --> 2.304040).  Saving model ...\n",
      "Epoch: 2/45 \tTraining Loss: 2.457915 \tValidation Loss: 2.418982\n",
      "Validation loss decreased (2.304040 --> 2.216955).  Saving model ...\n",
      "Epoch: 3/45 \tTraining Loss: 2.362300 \tValidation Loss: 2.359848\n",
      "Validation loss decreased (2.216955 --> 2.195448).  Saving model ...\n",
      "Epoch: 4/45 \tTraining Loss: 2.305146 \tValidation Loss: 2.300002\n",
      "Validation loss decreased (2.195448 --> 2.158740).  Saving model ...\n",
      "Validation loss decreased (2.158740 --> 2.153316).  Saving model ...\n",
      "Validation loss decreased (2.153316 --> 2.090712).  Saving model ...\n",
      "Epoch: 5/45 \tTraining Loss: 2.230006 \tValidation Loss: 2.229824\n",
      "Validation loss decreased (2.090712 --> 2.077376).  Saving model ...\n",
      "Validation loss decreased (2.077376 --> 2.071847).  Saving model ...\n",
      "Epoch: 6/45 \tTraining Loss: 2.181299 \tValidation Loss: 2.189614\n",
      "Validation loss decreased (2.071847 --> 2.027649).  Saving model ...\n",
      "Validation loss decreased (2.027649 --> 1.979463).  Saving model ...\n",
      "Epoch: 7/45 \tTraining Loss: 2.159875 \tValidation Loss: 2.169194\n",
      "Epoch: 8/45 \tTraining Loss: 2.097832 \tValidation Loss: 2.118807\n",
      "Validation loss decreased (1.979463 --> 1.959043).  Saving model ...\n",
      "Epoch: 9/45 \tTraining Loss: 2.075069 \tValidation Loss: 2.136208\n",
      "Validation loss decreased (1.959043 --> 1.937086).  Saving model ...\n",
      "Epoch: 10/45 \tTraining Loss: 2.064042 \tValidation Loss: 2.094529\n",
      "Validation loss decreased (1.937086 --> 1.936613).  Saving model ...\n",
      "Epoch: 11/45 \tTraining Loss: 2.034306 \tValidation Loss: 2.086356\n",
      "Epoch: 12/45 \tTraining Loss: 2.034409 \tValidation Loss: 2.078566\n",
      "Validation loss decreased (1.936613 --> 1.909715).  Saving model ...\n",
      "Epoch: 13/45 \tTraining Loss: 2.010969 \tValidation Loss: 2.025692\n",
      "Epoch: 14/45 \tTraining Loss: 1.980464 \tValidation Loss: 2.020627\n",
      "Epoch: 15/45 \tTraining Loss: 1.971037 \tValidation Loss: 2.022802\n",
      "Validation loss decreased (1.909715 --> 1.897988).  Saving model ...\n",
      "Validation loss decreased (1.897988 --> 1.890059).  Saving model ...\n",
      "Epoch: 16/45 \tTraining Loss: 1.970381 \tValidation Loss: 2.013933\n",
      "Epoch: 17/45 \tTraining Loss: 1.961433 \tValidation Loss: 2.013846\n",
      "Epoch: 18/45 \tTraining Loss: 1.972377 \tValidation Loss: 2.029758\n",
      "Epoch: 19/45 \tTraining Loss: 1.955105 \tValidation Loss: 1.996936\n",
      "Epoch: 20/45 \tTraining Loss: 1.954300 \tValidation Loss: 2.039472\n",
      "Validation loss decreased (1.890059 --> 1.877166).  Saving model ...\n",
      "Epoch: 21/45 \tTraining Loss: 1.967908 \tValidation Loss: 1.989703\n",
      "Validation loss decreased (1.877166 --> 1.859898).  Saving model ...\n",
      "Epoch: 22/45 \tTraining Loss: 1.940858 \tValidation Loss: 1.974025\n",
      "Epoch: 23/45 \tTraining Loss: 1.931039 \tValidation Loss: 1.979199\n",
      "Epoch: 24/45 \tTraining Loss: 1.932822 \tValidation Loss: 1.974701\n",
      "Epoch: 25/45 \tTraining Loss: 1.922716 \tValidation Loss: 1.978477\n",
      "Epoch: 26/45 \tTraining Loss: 1.927452 \tValidation Loss: 1.977563\n",
      "Epoch: 27/45 \tTraining Loss: 1.919059 \tValidation Loss: 1.980798\n",
      "Epoch: 28/45 \tTraining Loss: 1.918520 \tValidation Loss: 1.990852\n",
      "Epoch: 29/45 \tTraining Loss: 1.915777 \tValidation Loss: 1.979325\n",
      "Epoch: 30/45 \tTraining Loss: 1.934812 \tValidation Loss: 1.984905\n",
      "Epoch: 31/45 \tTraining Loss: 1.924342 \tValidation Loss: 1.980481\n",
      "Epoch: 32/45 \tTraining Loss: 1.921187 \tValidation Loss: 1.982132\n",
      "Epoch: 33/45 \tTraining Loss: 1.934868 \tValidation Loss: 1.980335\n",
      "Validation loss decreased (1.859898 --> 1.854241).  Saving model ...\n",
      "Epoch: 34/45 \tTraining Loss: 1.924242 \tValidation Loss: 1.989049\n",
      "Validation loss decreased (1.854241 --> 1.838431).  Saving model ...\n",
      "Epoch: 35/45 \tTraining Loss: 1.917437 \tValidation Loss: 1.962663\n",
      "Epoch: 36/45 \tTraining Loss: 1.917858 \tValidation Loss: 1.962391\n",
      "Epoch: 37/45 \tTraining Loss: 1.919275 \tValidation Loss: 1.972969\n",
      "Epoch: 38/45 \tTraining Loss: 1.927458 \tValidation Loss: 1.993628\n",
      "Epoch: 39/45 \tTraining Loss: 1.938825 \tValidation Loss: 1.988368\n",
      "Epoch: 40/45 \tTraining Loss: 1.934901 \tValidation Loss: 1.980752\n",
      "Epoch: 41/45 \tTraining Loss: 1.921564 \tValidation Loss: 1.969279\n",
      "Epoch: 42/45 \tTraining Loss: 1.911132 \tValidation Loss: 1.956476\n",
      "Epoch: 43/45 \tTraining Loss: 1.911255 \tValidation Loss: 1.955184\n",
      "Epoch: 44/45 \tTraining Loss: 1.917457 \tValidation Loss: 1.956635\n",
      "Epoch: 45/45 \tTraining Loss: 1.943287 \tValidation Loss: 1.979269\n"
     ]
    }
   ],
   "source": [
    "train(epochs,train_loader,model,valid_loader,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d451cfb4-c60d-4dad-bfd8-75f2d64f28c4",
   "metadata": {},
   "source": [
    "## Training without Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1f49059-0f50-4109-9915-be4c571c76ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU_RNN(\n",
      "  (gru): GRU(300, 32, num_layers=2, batch_first=True, dropout=6e-06)\n",
      "  (linear): Linear(in_features=32, out_features=15, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (func): Softmax(dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model     = GRU_RNN(input_dim, output_dim, hidden_dim, n_layers,att=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a46164b3-eeba-414b-a5d9-49b7f6561421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 2.413459).  Saving model ...\n",
      "Validation loss decreased (2.413459 --> 2.288238).  Saving model ...\n",
      "Validation loss decreased (2.288238 --> 2.267991).  Saving model ...\n",
      "Epoch: 1/45 \tTraining Loss: 2.555125 \tValidation Loss: 2.403512\n",
      "Validation loss decreased (2.267991 --> 2.135175).  Saving model ...\n",
      "Epoch: 2/45 \tTraining Loss: 2.284556 \tValidation Loss: 2.251288\n",
      "Validation loss decreased (2.135175 --> 2.010185).  Saving model ...\n",
      "Epoch: 3/45 \tTraining Loss: 2.168519 \tValidation Loss: 2.175147\n",
      "Validation loss decreased (2.010185 --> 2.000897).  Saving model ...\n",
      "Epoch: 4/45 \tTraining Loss: 2.112263 \tValidation Loss: 2.165599\n",
      "Epoch: 5/45 \tTraining Loss: 2.076881 \tValidation Loss: 2.138372\n",
      "Epoch: 6/45 \tTraining Loss: 2.054630 \tValidation Loss: 2.120766\n",
      "Epoch: 7/45 \tTraining Loss: 2.035374 \tValidation Loss: 2.117952\n",
      "Validation loss decreased (2.000897 --> 1.956686).  Saving model ...\n",
      "Epoch: 8/45 \tTraining Loss: 2.043953 \tValidation Loss: 2.115788\n",
      "Epoch: 9/45 \tTraining Loss: 2.026250 \tValidation Loss: 2.097490\n",
      "Epoch: 10/45 \tTraining Loss: 2.004428 \tValidation Loss: 2.101424\n",
      "Epoch: 11/45 \tTraining Loss: 2.002990 \tValidation Loss: 2.107551\n",
      "Epoch: 12/45 \tTraining Loss: 2.009701 \tValidation Loss: 2.107053\n",
      "Epoch: 13/45 \tTraining Loss: 2.006640 \tValidation Loss: 2.102857\n",
      "Epoch: 14/45 \tTraining Loss: 2.010975 \tValidation Loss: 2.116301\n",
      "Validation loss decreased (1.956686 --> 1.917972).  Saving model ...\n",
      "Epoch: 15/45 \tTraining Loss: 2.021651 \tValidation Loss: 2.123695\n",
      "Epoch: 16/45 \tTraining Loss: 2.005918 \tValidation Loss: 2.107858\n",
      "Epoch: 17/45 \tTraining Loss: 1.987436 \tValidation Loss: 2.100349\n",
      "Epoch: 18/45 \tTraining Loss: 1.978645 \tValidation Loss: 2.096797\n",
      "Epoch: 19/45 \tTraining Loss: 1.973355 \tValidation Loss: 2.108664\n",
      "Epoch: 20/45 \tTraining Loss: 1.976344 \tValidation Loss: 2.077388\n",
      "Epoch: 21/45 \tTraining Loss: 1.975359 \tValidation Loss: 2.081072\n",
      "Validation loss decreased (1.917972 --> 1.901195).  Saving model ...\n",
      "Epoch: 22/45 \tTraining Loss: 1.963503 \tValidation Loss: 2.071328\n",
      "Epoch: 23/45 \tTraining Loss: 1.975962 \tValidation Loss: 2.083158\n",
      "Epoch: 24/45 \tTraining Loss: 1.959941 \tValidation Loss: 2.053431\n",
      "Epoch: 25/45 \tTraining Loss: 1.978361 \tValidation Loss: 2.091306\n",
      "Epoch: 26/45 \tTraining Loss: 1.993598 \tValidation Loss: 2.097494\n",
      "Epoch: 27/45 \tTraining Loss: 1.968262 \tValidation Loss: 2.085063\n",
      "Epoch: 28/45 \tTraining Loss: 1.978736 \tValidation Loss: 2.058533\n",
      "Epoch: 29/45 \tTraining Loss: 1.967040 \tValidation Loss: 2.109438\n",
      "Epoch: 30/45 \tTraining Loss: 1.997978 \tValidation Loss: 2.080189\n",
      "Epoch: 31/45 \tTraining Loss: 1.969836 \tValidation Loss: 2.064535\n",
      "Epoch: 32/45 \tTraining Loss: 1.962388 \tValidation Loss: 2.058457\n",
      "Epoch: 33/45 \tTraining Loss: 1.968990 \tValidation Loss: 2.073843\n",
      "Epoch: 34/45 \tTraining Loss: 1.978344 \tValidation Loss: 2.082917\n",
      "Epoch: 35/45 \tTraining Loss: 1.979810 \tValidation Loss: 2.067924\n",
      "Epoch: 36/45 \tTraining Loss: 1.971462 \tValidation Loss: 2.076883\n",
      "Epoch: 37/45 \tTraining Loss: 1.980857 \tValidation Loss: 2.087954\n",
      "Epoch: 38/45 \tTraining Loss: 1.976077 \tValidation Loss: 2.090263\n",
      "Epoch: 39/45 \tTraining Loss: 1.973334 \tValidation Loss: 2.078146\n",
      "Epoch: 40/45 \tTraining Loss: 1.967681 \tValidation Loss: 2.106318\n",
      "Epoch: 41/45 \tTraining Loss: 1.956381 \tValidation Loss: 2.075821\n",
      "Epoch: 42/45 \tTraining Loss: 1.959319 \tValidation Loss: 2.065286\n",
      "Epoch: 43/45 \tTraining Loss: 1.968653 \tValidation Loss: 2.077078\n",
      "Epoch: 44/45 \tTraining Loss: 1.957790 \tValidation Loss: 2.066110\n",
      "Epoch: 45/45 \tTraining Loss: 1.964568 \tValidation Loss: 2.083749\n"
     ]
    }
   ],
   "source": [
    "train(epochs,train_loader,model,valid_loader,optimizer,criterion,att=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca13d955-6efa-41c1-af86-a269d3c19e65",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "274e26e7-26be-44fb-864a-29508d82fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader,net):\n",
    "    v_c = 0\n",
    "    net.eval()\n",
    "    num_correct = 0\n",
    "    valid_acc = 0\n",
    "    h = net.init_hidden(batch_size)\n",
    "    for inputs, labels in test_loader:\n",
    "        v_c += 1\n",
    "        if (v_c == 65):\n",
    "            continue\n",
    "        h = h.data\n",
    "        inputs, labels = inputs.to(device), labels.type(torch.LongTensor).to(device)\n",
    "\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        pred = torch.round(output.squeeze()) \n",
    "        top_value, top_index = torch.max(pred,1)\n",
    "        correct_tensor = top_index.eq(labels.float().view_as(top_index))\n",
    "        correct = np.squeeze(correct_tensor.to('cpu').numpy())\n",
    "        num_correct += np.sum(correct)\n",
    "    \n",
    "    test_acc = num_correct/len(test_loader.dataset)\n",
    "    print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f9273c-b2bc-4934-9e2b-0e0d9a74e0d7",
   "metadata": {},
   "source": [
    "## Accuracy with Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e38fa47f-8036-4646-ad00-2e022d9df2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('RNN_GRU_Att.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbd08da8-e8cf-4c73-8774-5493094a744b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.823\n"
     ]
    }
   ],
   "source": [
    "test(test_loader,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d52f2a7-eb3e-4b5b-8450-2b105fc9ef0c",
   "metadata": {},
   "source": [
    "## Accuracy without Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e7ae841-f3ea-4c57-839c-a93409fea501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('RNN_GRU.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8dd6562-1f7f-4278-9400-7c2de56a17e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.786\n"
     ]
    }
   ],
   "source": [
    "test(test_loader,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5d8b39-306a-4c53-97ad-dade7a5f6080",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Adding an Attention Layer has increased the model accuracy as expected.\n",
    "The model furthur can be extended/improved by using other methods such as `transformers`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}